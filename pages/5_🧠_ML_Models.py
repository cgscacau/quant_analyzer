# pages/5_ü§ñ_ML_Models.py
from __future__ import annotations

import math
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import streamlit as st
import yfinance as yf
from sklearn.ensemble import (
    RandomForestClassifier,
    HistGradientBoostingClassifier,
    StackingClassifier,
)
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
)
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler


# ------------------------------------------------------------
# Config da p√°gina
# ------------------------------------------------------------
st.set_page_config(page_title="ML Models", page_icon="ü§ñ", layout="wide")


# ------------------------------------------------------------
# Watchlists (fallback seguro)
# ------------------------------------------------------------
def _load_watchlists_safe() -> Dict[str, List[str]]:
    try:
        from core.data import load_watchlists as _lw  # opcional, se existir
        return _lw()
    except Exception:
        return {
            "BR_STOCKS": ["PETR4.SA", "VALE3.SA", "ITUB4.SA", "BBDC4.SA", "BBAS3.SA"],
            "FIIs": ["CPTS11.SA", "RBVA11.SA", "XPML11.SA", "RBRF11.SA", "GGRC11.SA", "HGBS11.SA", "KNCR11.SA"],
            "US_STOCKS": ["AAPL", "MSFT", "NVDA", "AMZN", "GOOGL", "META"],
            "CRYPTO": ["BTC-USD", "ETH-USD", "SOL-USD"],
        }


def _flatten_unique(lst_of_lists: List[List[str]]) -> List[str]:
    out, seen = [], set()
    for lst in lst_of_lists:
        for x in lst:
            if x not in seen:
                seen.add(x)
                out.append(x)
    return out


# ------------------------------------------------------------
# Download robusto (com cache)
# ------------------------------------------------------------
@st.cache_data(show_spinner=False, ttl=900)
def download_history_batch(
    tickers: List[str], period: str, interval: str, min_rows: int = 100
) -> Dict[str, pd.DataFrame]:
    """Baixa candles via yfinance e retorna apenas os ativos v√°lidos."""
    if not tickers:
        return {}

    tickers = list(dict.fromkeys([t.strip() for t in tickers if t and isinstance(t, str)]))

    # 1 ticker
    if len(tickers) == 1:
        df = yf.download(
            tickers[0], period=period, interval=interval,
            auto_adjust=False, threads=True, progress=False
        )
        if isinstance(df, pd.DataFrame) and not df.empty:
            df = df.dropna(how="all")
            ok_cols = {"Open", "High", "Low", "Close", "Adj Close", "Volume"} & set(map(str, df.columns))
            if len(df) >= min_rows and ok_cols:
                return {tickers[0]: df.copy()}
        return {}

    # Muitos tickers (MultiIndex)
    df = yf.download(
        tickers, period=period, interval=interval,
        group_by="ticker", auto_adjust=False, threads=True, progress=False
    )
    out: Dict[str, pd.DataFrame] = {}
    if isinstance(df, pd.DataFrame) and not df.empty:
        for t in tickers:
            try:
                sub = df[t].copy()
            except Exception:
                continue
            if not isinstance(sub, pd.DataFrame) or sub.empty:
                continue
            sub = sub.dropna(how="all")
            ok_cols = {"Open", "High", "Low", "Close", "Adj Close", "Volume"} & set(map(str, sub.columns))
            if len(sub) >= min_rows and ok_cols:
                out[t] = sub
    return out


def _choose_close_col(df: pd.DataFrame) -> pd.Series:
    if "Adj Close" in df.columns:
        return df["Adj Close"]
    if "Close" in df.columns:
        return df["Close"]
    return pd.Series(dtype=float, index=df.index)


# ------------------------------------------------------------
# Features & Target
# ------------------------------------------------------------
def rsi_series(close: pd.Series, length: int = 14) -> pd.Series:
    delta = close.diff()
    gain = delta.clip(lower=0.0)
    loss = -delta.clip(upper=0.0)
    avg_gain = gain.ewm(alpha=1 / length, adjust=False).mean()
    avg_loss = loss.ewm(alpha=1 / length, adjust=False).mean()
    rs = avg_gain / avg_loss.replace(0, np.nan)
    rsi = 100 - (100 / (1 + rs))
    return rsi.fillna(50.0)


def macd(close: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[pd.Series, pd.Series]:
    ema_f = close.ewm(span=fast, adjust=False).mean()
    ema_s = close.ewm(span=slow, adjust=False).mean()
    macd_line = ema_f - ema_s
    macd_signal = macd_line.ewm(span=signal, adjust=False).mean()
    return macd_line, macd_signal


def build_dataset(
    df: pd.DataFrame,
    rsi_len: int,
    sma_fast: int,
    sma_slow: int,
    vol_win: int,
    n_lags: int,
) -> pd.DataFrame:
    """Monta features e alvo (y = pr√≥xima barra de alta)."""
    close = _choose_close_col(df)
    if close.empty:
        return pd.DataFrame()

    ret = close.pct_change()

    # Features b√°sicas
    feat = pd.DataFrame(index=close.index)
    feat["ret"] = ret
    feat["rsi"] = rsi_series(close, rsi_len)
    feat["sma_fast"] = close.rolling(sma_fast).mean()
    feat["sma_slow"] = close.rolling(sma_slow).mean()
    feat["sma_cross_strength"] = (feat["sma_fast"] - feat["sma_slow"]) / (feat["sma_slow"] + 1e-9)
    feat["vol"] = ret.rolling(vol_win).std()

    # MACD
    macd_line, macd_sig = macd(close)
    feat["macd"] = macd_line
    feat["macd_sig"] = macd_sig
    feat["macd_hist"] = macd_line - macd_sig

    # Lags de retorno
    for k in range(1, n_lags + 1):
        feat[f"ret_lag{k}"] = ret.shift(k)

    # Alvo: pr√≥xima barra sobe?
    feat["ret_next"] = ret.shift(-1)
    feat["y"] = (feat["ret_next"] > 0).astype(int)

    feat = feat.dropna()
    return feat


# ------------------------------------------------------------
# Treino e avalia√ß√£o (TimeSeriesSplit OOF)
# ------------------------------------------------------------
def fit_oof_predict_proba(
    X: pd.DataFrame,
    y: pd.Series,
    model_type: str,
    rf_n_estimators: int,
    rf_max_depth: int,
) -> Tuple[np.ndarray, Dict[str, float]]:
    """
    Faz OOF com TimeSeriesSplit (walk-forward) e retorna proba prevista (classe 1) e m√©tricas m√©dias.
    """
    tscv = TimeSeriesSplit(n_splits=5)
    proba_oof = np.full(shape=len(X), fill_value=np.nan, dtype=float)

    # Modelos
    if model_type == "Logistic":
        base = LogisticRegression(max_iter=2000)
        scaler = StandardScaler()
        needs_scale = True
    elif model_type == "RandomForest":
        base = RandomForestClassifier(
            n_estimators=rf_n_estimators, max_depth=None if rf_max_depth <= 0 else rf_max_depth,
            random_state=7, n_jobs=-1
        )
        needs_scale = False
        scaler = None
    elif model_type == "HistGB":
        base = HistGradientBoostingClassifier(random_state=7)
        needs_scale = False
        scaler = None
    else:  # Stacking (RF + HGB + LR)
        rf = RandomForestClassifier(n_estimators=rf_n_estimators, random_state=7, n_jobs=-1)
        hgb = HistGradientBoostingClassifier(random_state=7)
        lr = LogisticRegression(max_iter=2000)
        estimators = [("rf", rf), ("hgb", hgb)]
        base = StackingClassifier(estimators=estimators, final_estimator=lr, passthrough=True, n_jobs=-1)
        needs_scale = False
        scaler = None

    # OOF
    for tr_idx, te_idx in tscv.split(X):
        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]
        y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]

        if needs_scale:
            scaler.fit(X_tr)
            X_tr2 = pd.DataFrame(scaler.transform(X_tr), index=X_tr.index, columns=X_tr.columns)
            X_te2 = pd.DataFrame(scaler.transform(X_te), index=X_te.index, columns=X_te.columns)
        else:
            X_tr2, X_te2 = X_tr, X_te

        base.fit(X_tr2, y_tr)
        if hasattr(base, "predict_proba"):
            p = base.predict_proba(X_te2)[:, 1]
        else:
            # modelos sem predict_proba
            p = base.predict(X_te2).astype(float)

        proba_oof[te_idx] = p

    # M√©tricas em OOF (descarta NaN do in√≠cio)
    mask = ~np.isnan(proba_oof)
    y_valid = y.iloc[mask]
    p_valid = proba_oof[mask]

    preds = (p_valid >= 0.5).astype(int)
    metrics = {
        "Accuracy": float(accuracy_score(y_valid, preds)),
        "Precision": float(precision_score(y_valid, preds, zero_division=0)),
        "Recall": float(recall_score(y_valid, preds, zero_division=0)),
        "F1": float(f1_score(y_valid, preds, zero_division=0)),
        "ROC_AUC": float(roc_auc_score(y_valid, p_valid)) if len(np.unique(y_valid)) > 1 else 0.5,
    }
    return proba_oof, metrics


def strategy_from_proba(
    proba: np.ndarray,
    ret_next: pd.Series,
    buy_threshold: float,
    cost_bps_side: float = 0.0,
) -> pd.Series:
    """
    Gera equity usando proba OOF (compra em t se proba(t)‚â•th e realiza em t+1).
    Custo por mudan√ßa de posi√ß√£o (bps) aplicado em varia√ß√µes 0->1 e 1->0.
    """
    if ret_next.empty:
        return pd.Series([], dtype=float)

    p = pd.Series(proba, index=ret_next.index)
    p = p.dropna()
    retn = ret_next.loc[p.index]

    pos = (p >= buy_threshold).astype(int)
    # retorno com posi√ß√£o (entrada no pr√≥ximo candle √© aproximada com OOF)
    strat_ret = retn * pos

    # custos
    changes = pos.diff().abs().fillna(0.0)
    bps_cost = cost_bps_side / 10000.0
    strat_ret = strat_ret - changes * bps_cost

    equity = (1.0 + strat_ret.fillna(0.0)).cumprod()
    return equity


def _metrics_from_equity(equity: pd.Series, ret_freq: str = "D") -> Tuple[float, float, float]:
    if equity.empty or len(equity) < 2:
        return 0.0, 0.0, 0.0

    total_ret = equity.iloc[-1]
    days = (equity.index[-1] - equity.index[0]).days or 1
    years = days / 365.25
    cagr = (total_ret ** (1 / years) - 1) if total_ret > 0 and years > 0 else 0.0

    rets = equity.pct_change().dropna()
    if rets.empty:
        sharpe = 0.0
    else:
        ann = 252 if ret_freq.upper().startswith("D") else 52
        sharpe = (rets.mean() / (rets.std() + 1e-9)) * math.sqrt(ann)

    roll_max = equity.cummax()
    dd = (equity / roll_max) - 1.0
    max_dd = dd.min() if len(dd) else 0.0

    return float(cagr), float(sharpe), float(abs(max_dd))


# ------------------------------------------------------------
# UI
# ------------------------------------------------------------
st.title("ü§ñ ML Models")
st.caption("Classifica√ß√£o de pr√≥xima barra (subida/queda) com Logistic / RF / HistGB / Stacking")

watch = _load_watchlists_safe()
universe = _flatten_unique(watch.values())
screener_sel = st.session_state.get("screener_selected", [])

use_screener = st.toggle(
    "Usar sele√ß√£o do Screener (se houver)",
    value=bool(screener_sel),
)
symbols_manual = st.multiselect(
    "Ativos para treinar",
    options=universe,
    default=(screener_sel or ["AAPL", "MSFT", "NVDA", "PETR4.SA"]),
    disabled=use_screener,
)
symbols = screener_sel if (use_screener and screener_sel) else symbols_manual

cols_top = st.columns(3)
with cols_top[0]:
    period = st.selectbox("Per√≠odo", ["6mo", "1y", "2y", "5y"], index=1)
with cols_top[1]:
    interval = st.selectbox("Intervalo", ["1d", "1h", "1wk"], index=0)
with cols_top[2]:
    dark_theme = st.toggle("Tema escuro", value=False)

st.markdown("### Features")
f1, f2, f3, f4, f5 = st.columns(5)
with f1:
    rsi_len = st.slider("RSI length", 5, 40, 14)
with f2:
    sma_fast = st.slider("SMA r√°pida", 5, 100, 10)
with f3:
    sma_slow = st.slider("SMA lenta", 10, 200, 30)
with f4:
    vol_win = st.slider("Janela de volatilidade", 5, 60, 20)
with f5:
    n_lags = st.slider("Lags de retorno", 0, 10, 5)

st.markdown("### Modelo")
mcol1, mcol2, mcol3 = st.columns(3)
with mcol1:
    model_type = st.radio("Tipo", ["RandomForest", "HistGB", "Logistic", "Stacking"], horizontal=False, index=0)
with mcol2:
    buy_threshold = st.slider("Limiar de compra (prob. de alta)", 0.5, 0.9, 0.55, step=0.01)
with mcol3:
    rf_n_estimators = st.slider("n_estimators (RF)", 50, 1000, 300, step=25)
    rf_max_depth = st.slider("max_depth (RF) (0=auto)", 0, 20, 0)

cst1, cst2 = st.columns(2)
with cst1:
    cost_bps_side = st.number_input("Custo por lado (bps)", min_value=0.0, value=0.0, step=0.25)
with cst2:
    show_prob_plot = st.toggle("Mostrar gr√°fico de probabilidade", value=True)

# ------------------------------------------------------------
# Download
# ------------------------------------------------------------
if not symbols:
    st.info("Nenhum ativo selecionado. Selecione no Screener e depois ative o toggle acima, ou escolha manualmente.")
    st.stop()

with st.spinner("Baixando dados..."):
    bars_map = download_history_batch(symbols, period, interval, min_rows=150)

mantidos = list(bars_map.keys())
descartados = [s for s in symbols if s not in mantidos]
st.caption(f"‚úì V√°lidos: {len(mantidos)} | ‚úó Sem dados: {len(descartados)}")
if descartados:
    st.caption(f"Descartados: {', '.join(descartados)}")

if not mantidos:
    st.warning("Nenhum ativo com dados v√°lidos. Tente outro per√≠odo/intervalo.")
    st.stop()

# ------------------------------------------------------------
# Treino / Avalia√ß√£o por ativo
# ------------------------------------------------------------
all_metrics = {}
equities = {}
prob_series_map = {}

for sym, df in bars_map.items():
    # Garante √≠ndice de datas
    if not isinstance(df.index, pd.DatetimeIndex):
        try:
            df = df.copy()
            df.index = pd.to_datetime(df.index)
        except Exception:
            continue

    ds = build_dataset(df, rsi_len, sma_fast, sma_slow, vol_win, n_lags)
    if ds.empty or ds.shape[0] < 150:
        continue

    features = [c for c in ds.columns if c not in ("y", "ret_next")]
    X = ds[features]
    y = ds["y"].astype(int)

    proba_oof, m = fit_oof_predict_proba(
        X=X, y=y, model_type=model_type,
        rf_n_estimators=rf_n_estimators, rf_max_depth=rf_max_depth
    )
    all_metrics[sym] = m

    # Estrat√©gia
    equity = strategy_from_proba(
        proba=proba_oof, ret_next=ds["ret_next"], buy_threshold=buy_threshold, cost_bps_side=cost_bps_side
    )
    equities[sym] = equity

    # Probabilidade para plot
    prob_series_map[sym] = pd.Series(proba_oof, index=ds.index)

if not all_metrics:
    st.warning("N√£o foi poss√≠vel treinar/avaliar (dados insuficientes ap√≥s filtros).")
    st.stop()

# ------------------------------------------------------------
# Tabela de m√©tricas (modelo) e desempenho (estrat√©gia)
# ------------------------------------------------------------
met_df = pd.DataFrame(all_metrics).T[
    ["Accuracy", "Precision", "Recall", "F1", "ROC_AUC"]
].sort_values(by=["ROC_AUC", "F1"], ascending=False)
met_df = met_df.round(4)

# Estrat√©gia
perf_rows = {}
for sym, eq in equities.items():
    cagr, sharpe, mdd = _metrics_from_equity(eq)
    perf_rows[sym] = {"CAGR%": 100 * cagr, "Sharpe": sharpe, "MaxDD%": 100 * mdd}
perf_df = pd.DataFrame(perf_rows).T[["CAGR%", "Sharpe", "MaxDD%"]].sort_values(by=["CAGR%", "Sharpe"], ascending=False)
perf_df = perf_df.round({"CAGR%": 2, "MaxDD%": 2, "Sharpe": 2})

st.subheader("M√©tricas do Modelo (OOF)")
st.dataframe(met_df, use_container_width=True, height=260)

st.subheader("Desempenho da Estrat√©gia (prob ‚â• limiar)")
st.dataframe(perf_df, use_container_width=True, height=240)

best = perf_df.index[0]
st.success(f"Melhor por CAGR: **{best}** (CAGR {perf_df.loc[best, 'CAGR%']:.2f}%, Sharpe {perf_df.loc[best, 'Sharpe']:.2f})")

# ------------------------------------------------------------
# Gr√°ficos
# ------------------------------------------------------------
template = "plotly_dark" if dark_theme else "plotly"
tabs = st.tabs([f"{s}" for s in equities.keys()])

for tab, sym in zip(tabs, equities.keys()):
    with tab:
        eq = equities[sym]
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=eq.index, y=eq.values, mode="lines", name="Equity"))
        fig.update_layout(
            template=template, height=360, margin=dict(l=10, r=10, t=30, b=10),
            title=f"{sym} ‚Äî Equity (ML strategy)", yaxis_title="Equity", xaxis_title="Tempo"
        )
        st.plotly_chart(fig, use_container_width=True)

        if show_prob_plot and sym in prob_series_map:
            p = prob_series_map[sym].dropna()
            thr = pd.Series(buy_threshold, index=p.index)
            fig2 = go.Figure()
            fig2.add_trace(go.Scatter(x=p.index, y=p.values, name="P(up) OOF", mode="lines"))
            fig2.add_trace(go.Scatter(x=thr.index, y=thr.values, name="Limiar", mode="lines", line=dict(dash="dash")))
            fig2.update_layout(
                template=template, height=260, margin=dict(l=10, r=10, t=30, b=10),
                title=f"{sym} ‚Äî Probabilidade prevista (OOF)", yaxis_title="P(up)", xaxis_title="Tempo"
            )
            st.plotly_chart(fig2, use_container_width=True)

#===================================================================================================================================================================================================================
#===================================================================================================================================================================================================================
#===================================================================================================================================================================================================================
#===================================================================================================================================================================================================================


# ============================================================
# üîΩ RESUMOZ√ÉO FINAL ‚Äî vencedores + situa√ß√£o atual por ativo
# Cole a partir daqui no FINAL da p√°gina
# ============================================================

#import numpy as np
#import pandas as pd
#import streamlit as st

# ---------- helpers de formata√ß√£o ----------
def _fmt_pct_smart(v):
    if v is None or (isinstance(v, float) and not np.isfinite(v)):
        return "‚Äî"
    try:
        v = float(v)
    except Exception:
        return "‚Äî"
    # se parecer probabilidade 0‚Äì1, vira %
    return f"{(v*100 if -1.5 <= v <= 1.5 else v):.2f}%"

def _coalesce(*xs):
    for x in xs:
        if x is not None:
            return x
    return None

# ---------- (1) Tente descobrir vari√°veis do seu notebook ----------
# PERF (tabela de desempenho por ativo)
_perf_candidates = [locals().get(n) for n in ["perf", "perf_df", "strat_df", "performance_df", "strategy_df"]]
PERF_DF = next((x for x in _perf_candidates if isinstance(x, pd.DataFrame) and len(x) > 0), None)

# PROBABILIDADES (dict[str, Series] OU DataFrame col=ativo)
_proba_candidates = [locals().get(n) for n in ["proba_dict", "pred_proba", "probas", "proba_df"]]
PROBA = next((x for x in _proba_candidates if x is not None), None)

# SINAIS (opcional) ‚Äî dict[str, Series] OU DataFrame col=ativo (0/1, -1/0/1‚Ä¶)
_signal_candidates = [locals().get(n) for n in ["signal_dict", "signals", "sig_df"]]
SIGNALS = next((x for x in _signal_candidates if x is not None), None)

# LIMIAR (probability threshold)
THRESH = _coalesce(locals().get("threshold"), locals().get("prob_threshold"), locals().get("thresh"), 0.5)

# PRE√áOS (opcional) ‚Äî p/ varia√ß√£o di√°ria
_prices_candidates = [locals().get(n) for n in ["prices", "close_df", "closes", "px_df"]]
PRICES = next((x for x in _prices_candidates if isinstance(x, pd.DataFrame) and len(x) > 0), None)

# ---------- (2) Normalizar a tabela de performance ----------
def _normalize_perf(df: pd.DataFrame) -> pd.DataFrame:
    d = df.copy()
    # mover ativo para √≠ndice se vier em coluna
    if d.index.name is None:
        # tentativa: achar coluna de ativo
        for c in ["asset", "ativo", "symbol", "ticker"]:
            if c in [x.lower() for x in d.columns.astype(str)]:
                real = [col for col in d.columns if col.lower() == c][0]
                d = d.set_index(real)
                break
    # renomear colunas por padr√£o
    ren = {}
    for c in d.columns:
        cl = str(c).lower().replace("%", "").strip()
        if "cagr" in cl or "ret" in cl:
            ren[c] = "cagr"
        elif "sharpe" in cl:
            ren[c] = "sharpe"
        elif "maxdd" in cl or ("dd" in cl and "avg" not in cl):
            ren[c] = "maxdd"
    d = d.rename(columns=ren)
    keep = [c for c in ["cagr", "sharpe", "maxdd"] if c in d.columns]
    return d[keep].apply(pd.to_numeric, errors="coerce")

if not isinstance(PERF_DF, pd.DataFrame) or PERF_DF.empty:
    st.warning("Resumo: n√£o encontrei a tabela de performance (ex.: perf_df/strat_df).")
else:
    perf_norm = _normalize_perf(PERF_DF).dropna(how="all")
    if perf_norm.empty:
        st.warning("Resumo: a tabela de performance n√£o tem colunas reconhecidas (CAGR/Sharpe/MaxDD).")
    else:
        # vencedores
        best_cagr = perf_norm["cagr"].astype(float).idxmax() if "cagr" in perf_norm else None
        best_sharpe = perf_norm["sharpe"].astype(float).idxmax() if "sharpe" in perf_norm else None
        best_dd = perf_norm["maxdd"].astype(float).idxmin() if "maxdd" in perf_norm else None

        val_cagr = perf_norm.loc[best_cagr, "cagr"] if best_cagr is not None else None
        val_sharpe = perf_norm.loc[best_sharpe, "sharpe"] if best_sharpe is not None else None
        val_dd = perf_norm.loc[best_dd, "maxdd"] if best_dd is not None else None

        # ---------- (3) Cabe√ßalho ‚Äúletras grandes‚Äù ----------
        st.markdown(
            f"""
            <div style="border-radius:14px;padding:14px 16px;margin:6px 0;background:linear-gradient(135deg,#0b6,#094);color:white;font-size:15px">
              <b>Resumo da Estrat√©gia</b> ‚Äî 
              Melhor <b>CAGR</b>: <span style="font-size:20px">{best_cagr or '‚Äî'}</span> ({_fmt_pct_smart(val_cagr)}) &nbsp;‚Ä¢&nbsp;
              Melhor <b>Sharpe</b>: <span style="font-size:20px">{best_sharpe or '‚Äî'}</span> ({val_sharpe:.2f} se dispon√≠vel) &nbsp;‚Ä¢&nbsp;
              Menor <b>MaxDD</b>: <span style="font-size:20px">{best_dd or '‚Äî'}</span> ({_fmt_pct_smart(val_dd)})
            </div>
            """,
            unsafe_allow_html=True,
        )

        # ---------- (4) Situa√ß√£o atual por ativo ----------
        def _last_from(obj, key):
            """aceita dict[str, Series] OU DataFrame com colunas=ativos"""
            try:
                if isinstance(obj, dict) and key in obj and isinstance(obj[key], pd.Series) and len(obj[key]):
                    return float(obj[key].iloc[-1])
                if isinstance(obj, pd.DataFrame) and key in obj.columns and len(obj[key]):
                    return float(obj[key].iloc[-1])
            except Exception:
                pass
            return None

        ativos = list(perf_norm.index.astype(str))
        rows = []
        for a in ativos:
            p = _last_from(PROBA, a)
            s = _last_from(SIGNALS, a)
            # regra de decis√£o: se tiver sinal expl√≠cito, usa; sen√£o deriva de prob vs limiar
            if s is None and p is not None:
                s = 1.0 if p >= float(THRESH) else 0.0
            estado = "LONG" if s is not None and s > 0 else ("SHORT" if s is not None and s < 0 else "OUT")

            # varia√ß√£o di√°ria opcional (se tiver pre√ßos)
            d1 = None
            if isinstance(PRICES, pd.DataFrame) and a in PRICES.columns and len(PRICES[a]) > 1:
                try:
                    d1 = float(PRICES[a].iloc[-1] / PRICES[a].iloc[-2] - 1.0)
                except Exception:
                    d1 = None

            rows.append({
                "Ativo": a,
                "Prob‚Üë (√∫ltima)": _fmt_pct_smart(p),
                "Limiar": _fmt_pct_smart(THRESH),
                "Sinal": estado,
                "CAGR": _fmt_pct_smart(perf_norm.loc[a, "cagr"]) if "cagr" in perf_norm else "‚Äî",
                "Sharpe": f"{float(perf_norm.loc[a, 'sharpe']):.2f}" if "sharpe" in perf_norm and np.isfinite(perf_norm.loc[a, 'sharpe']) else "‚Äî",
                "MaxDD": _fmt_pct_smart(perf_norm.loc[a, "maxdd"]) if "maxdd" in perf_norm else "‚Äî",
                "Œî1D pre√ßo": _fmt_pct_smart(d1),
            })

        st.markdown("### Situa√ß√£o atual por ativo")
        st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)

        # ---------- (5) Cards compactos (opcional ‚Äì destaques) ----------
        c1, c2, c3 = st.columns(3)
        c1.metric("üèÜ Melhor CAGR", best_cagr or "‚Äî", _fmt_pct_smart(val_cagr))
        c2.metric("‚≠ê Melhor Sharpe", best_sharpe or "‚Äî", f"{val_sharpe:.2f}" if val_sharpe is not None and np.isfinite(val_sharpe) else "‚Äî")
        c3.metric("üõ°Ô∏è Menor MaxDD", best_dd or "‚Äî", _fmt_pct_smart(val_dd))



